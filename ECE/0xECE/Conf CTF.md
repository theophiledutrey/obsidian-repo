# ğŸ§  CTFd + Chall-Manager + Terraform + Libvirt (Guide complet)

> Fiche **pas Ã  pas**, reproductible Ã  lâ€™identique, basÃ©e sur une installation fonctionnelle validÃ©e.  
> FormatÃ© pour **Obsidian** (Markdown).

---

## ğŸ¯ Objectif

Mettre en place une plateforme CTF capable de :

- DÃ©ployer **dynamiquement des VM par joueur**
    
- Via **CTFd + CTFd-Chall-Manager**
    
- En utilisant **Terraform + libvirt/KVM**
    
- Avec **cloud-init** pour la configuration initiale
    
- Nettoyage automatique via **Janitor**
    

---

## ğŸ§± Architecture finale

```
CTFd (UI)
  â”‚
  â”œâ”€â”€ Plugin ctfd-chall-manager
  â”‚       â”‚
  â”‚       â””â”€â”€ Chall-Manager (API)
  â”‚               â”œâ”€â”€ Terraform
  â”‚               â”œâ”€â”€ libvirt (socket host)
  â”‚               â”œâ”€â”€ mkisofs / cloud-init
  â”‚               â””â”€â”€ Registry OCI
  â”‚
  â””â”€â”€ MySQL / Redis / Nginx

VMs libvirt (sur le host)
```

---

## âš™ï¸ PrÃ©requis host

Sur la machine hÃ´te (Linux) :

```bash
sudo apt install -y \
  qemu-kvm \
  libvirt-daemon-system \
  libvirt-clients \
  virtinst \
  bridge-utils

sudo systemctl enable --now libvirtd
```

VÃ©rification :

```bash
virsh list --all
```

---

## ğŸ“¦ Ã‰tape 1 â€” Installation du plugin CTFd

Dans le repo CTFd :

```bash
cd CTFd/CTFd/plugins
git clone https://github.com/ctfer-io/ctfd-chall-manager.git
```

Puis redÃ©marrage :

```bash
docker compose down
docker compose up -d
```

---

## ğŸ§© Ã‰tape 2 â€” Docker Compose principal (CTFd + Chall-Manager)

### docker-compose.yml (extrait clÃ©)

```yaml
  chall-manager:
    build:
      context: .
      dockerfile: Dockerfile.chall-manager
    restart: always
    environment:
      OCI_INSECURE: true
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock
      - /var/run/libvirt/libvirt-sock:/var/run/libvirt/libvirt-sock
      - /dev/kvm:/dev/kvm
    networks:
      - default
      - internal

  chall-manager-janitor:
    image: ctferio/chall-manager-janitor:v0.6.1
    restart: always
    environment:
      URL: chall-manager:8080
      TICKER: 1m
```

âš ï¸ **Important** : `PLUGIN_SETTINGS_CM_API_URL=http://chall-manager:8080` dans le service `ctfd`

---

## ğŸ³ Ã‰tape 3 â€” Dockerfile chall-manager custom

### Dockerfile.chall-manager

```dockerfile
FROM ctferio/chall-manager:v0.6.1

USER root

RUN apt-get update && apt-get install -y \
    libvirt-clients \
    libvirt-daemon-system \
    qemu-kvm \
    genisoimage \
    xorriso \
    openssh-client \
    curl \
    ca-certificates \
    unzip \
    && rm -rf /var/lib/apt/lists/*

ENV TERRAFORM_VERSION=1.7.5

RUN curl -fsSL https://releases.hashicorp.com/terraform/${TERRAFORM_VERSION}/terraform_${TERRAFORM_VERSION}_linux_amd64.zip \
    -o /tmp/terraform.zip \
    && unzip /tmp/terraform.zip -d /usr/local/bin \
    && rm /tmp/terraform.zip
```

---

## ğŸ”¨ Ã‰tape 4 â€” Build & run

```bash
docker compose down
docker compose build --no-cache chall-manager
docker compose up -d
```

VÃ©rifications :

```bash
docker exec -it ctfd-chall-manager-1 terraform --version
docker exec -it ctfd-chall-manager-1 mkisofs --version
docker exec -it ctfd-chall-manager-1 virsh list --all
```

---

## ğŸ“¦ Ã‰tape 5 â€” Registry OCI locale

Dans docker-compose :

```yaml
  registry:
    image: registry:2
    ports:
      - 5000:5000
```

VÃ©rification :

```bash
curl http://localhost:5000/v2/_catalog
```

---

## ğŸ§ª Ã‰tape 6 â€” CrÃ©ation du scÃ©nario (docker-scenario)

### Arborescence

```
hack/docker-scenario/
â”œâ”€â”€ main.go
â”œâ”€â”€ main.tf
â”œâ”€â”€ cloud_init.cfg
â”œâ”€â”€ terraform.tfvars
â”œâ”€â”€ Pulumi.yaml
â”œâ”€â”€ build.sh
```

---

## ğŸ§  main.go (Pulumi / Chall-Manager)

- Utilise `command:local` pour lancer Terraform
    
- Copie les fichiers dans `/tmp/challmgr-<instance_id>`
    
- ExÃ©cute :
    

```bash
terraform init
terraform apply -auto-approve
```

- RÃ©cupÃ¨re les outputs (`ip`, `ssh_command`)
    

---

## â˜ï¸ cloud_init.cfg

- CrÃ©ation utilisateur `chall1`
    
- Mot de passe hashÃ©
    
- Installation de packages
    
- DÃ©pÃ´t du flag
    

---

## ğŸ§± main.tf (Terraform libvirt)

- libvirt_volume (image Ubuntu cloud)
    
- libvirt_cloudinit_disk
    
- libvirt_domain
    
- network `default`
    
- outputs :
    

```hcl
output "ip" {}
output "ssh_command" {}
```

---

## ğŸ“¤ Ã‰tape 7 â€” Build et push du scÃ©nario

### build.sh

```bash
#!/bin/bash

CGO_ENABLED=0 go build -o main main.go
REGISTRY=${REGISTRY:-"localhost:5000/"}

yq e -i '.runtime = {"name": "go", "options": {"binary": "./main"}}' Pulumi.yaml

oras push --insecure \
  "${REGISTRY}examples/terraform-libvirt:latest" \
  --artifact-type application/vnd.ctfer-io.scenario \
  main:application/vnd.ctfer-io.file \
  Pulumi.yaml:application/vnd.ctfer-io.file \
  main.tf:application/vnd.ctfer-io.file \
  cloud_init.cfg:application/vnd.ctfer-io.file \
  terraform.tfvars:application/vnd.ctfer-io.file
```

```bash
bash build.sh
```

---

## ğŸ® Ã‰tape 8 â€” CrÃ©ation du challenge dans CTFd

- Type : **Dynamic / Chall-Manager**
    
- Scenario :
    

```
registry:5000/examples/terraform-libvirt:latest
```

- Timeout, until, destroy on flag selon besoin
    

---

## ğŸš€ Ã‰tape 9 â€” Lancement dâ€™une instance

Dans CTFd â†’ **Launch instance**

Sur le host :

```bash
virsh list --all
```

RÃ©sultat attendu :

```
chall1-<id>   running
```

---

## ğŸ§¹ Ã‰tape 10 â€” Cleanup automatique

- GÃ©rÃ© par `chall-manager-janitor`
    
- Timeout
    
- Until
    
- Destroy on flag
    

---

## âœ… Ã‰tat final

âœ” Infra fonctionnelle  
âœ” Multi-instances  
âœ” Cloud-init  
âœ” Terraform  
âœ” Libvirt/KVM  
âœ” Nettoyage auto

---

## ğŸš€ AmÃ©liorations possibles

- Mot de passe unique par instance
    
- Affichage IP + SSH dans CTFd
    
- Hardening VM
    
- RÃ©seau isolÃ© par challenge
    
- Export infra en Terraform pur
    

---

## ğŸ Conclusion

Cette stack permet de dÃ©ployer des **challenges CTF rÃ©alistes, isolÃ©s et scalables**, comparables aux plateformes professionnelles.

ğŸ”¥ **ValidÃ© et reproductible.**